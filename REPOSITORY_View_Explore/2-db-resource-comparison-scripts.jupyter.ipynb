{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import the required lib\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "\n",
    "'''\n",
    "To get query condition string from reading the file :singleDBCondition\n",
    "and handle it to gain all parameters by split function\n",
    "'''\n",
    "DB_CONN_ID = ''\n",
    "END_TIME = ''\n",
    "INTERVAL = 0\n",
    "START_TIME = ''\n",
    "REPORT_TYPE = ''\n",
    "ISOK_ALL_PARA = 1\n",
    "DBs = []\n",
    "GENERAL_ERROR = None\n",
    "\n",
    "def handle_query_condition():\n",
    "    # To declare below variables are global variables\n",
    "    global DB_CONN_ID\n",
    "    global END_TIME\n",
    "    global INTERVAL\n",
    "    global START_TIME\n",
    "    global REPORT_TYPE\n",
    "    global ISOK_ALL_PARA\n",
    "    global DBs\n",
    "    global GENERAL_ERROR\n",
    "    \n",
    "    # To read parameters from singleDBCondition file\n",
    "    where_cause = !cat multipleDBWhereCondition\n",
    "    where_cause = re.search(r'DB_CONN_ID\\s?=\\s?.+END_TIME\\s?=\\s?.+INTERVAL\\s?=\\s?.+REPORT_TYPE\\s?=\\s?.+', where_cause[0])\n",
    "    GENERAL_ERROR = []\n",
    "    \n",
    "    if (where_cause <> None):\n",
    "        all_vars = where_cause.group().split(' ')\n",
    "        if len(all_vars) <> 4:\n",
    "            err_str = 'The format of parameters is error.'\n",
    "            if err_str not in GENERAL_ERROR:\n",
    "                GENERAL_ERROR.append(err_str)\n",
    "            ISOK_ALL_PARA = 0\n",
    "        else:# len(all_vars) == 4\n",
    "            # To get DB_CONN_ID\n",
    "            if (re.search(r'DB_CONN_ID\\s?=\\s?(.+)', all_vars[0]) == None):\n",
    "                err_str = 'The DB_CONN_ID can not be empty.'\n",
    "                if err_str not in GENERAL_ERROR:\n",
    "                    GENERAL_ERROR.append(err_str)\n",
    "                ISOK_ALL_PARA = 0\n",
    "            else:\n",
    "                DB_CONN_ID = re.search(r'DB_CONN_ID\\s?=\\s?(.+)', all_vars[0]).group(1)\n",
    "                DBs = DB_CONN_ID.split(',')\n",
    "\n",
    "            # To get the value of INTERVAL\n",
    "            if (re.search(r'INTERVAL\\s?=\\s?([0-9]+$)', all_vars[2]) == None):\n",
    "                err_str = 'The format of INTERVAL error.'\n",
    "                if err_str not in GENERAL_ERROR:\n",
    "                    GENERAL_ERROR.append(err_str)\n",
    "                ISOK_ALL_PARA = 0\n",
    "            else:\n",
    "                INTERVAL = int(re.search(r'(\\d+)', all_vars[2]).group())\n",
    "                if (INTERVAL > 50):  # most get 50 data for 2 dbs\n",
    "                    INTERVAL = 50\n",
    "\n",
    "            # To get START_TIME according to END_TIME\n",
    "            if (re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2})', all_vars[1]) == None) | ( re.search(r'(\\d{1,2}:\\d{1,2}:\\d{1,2})', all_vars[1]) == None):\n",
    "                err_str = 'The format of END_TIME error.'\n",
    "                if err_str not in GENERAL_ERROR:\n",
    "                    GENERAL_ERROR.append(err_str)\n",
    "                \n",
    "                ISOK_ALL_PARA = 0\n",
    "            else:\n",
    "                END_TIME = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2})', all_vars[1]).group() + ' ' + re.search( r'(\\d{1,2}:\\d{1,2}:\\d{1,2})', all_vars[1]).group()\n",
    "                def is_valid_datetime(END_TIME):\n",
    "                    try:\n",
    "                        time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                        return True\n",
    "                    except:\n",
    "                        return False\n",
    "                \n",
    "                if is_valid_datetime(END_TIME) == True:\n",
    "                    datetime_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                    # To slice datetime_tuple to gain exact time data\n",
    "                    year, month, day, hour, minute, second = datetime_tuple[:6]\n",
    "                    final_time = datetime.datetime(year, month, day, hour, minute, second) + datetime.timedelta(hours = -INTERVAL)\n",
    "                    # To transfer the datetime fields to string\n",
    "                    START_TIME = final_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                else:\n",
    "                    err_str = 'The format of END_TIME error.'\n",
    "                    if err_str not in GENERAL_ERROR:\n",
    "                        GENERAL_ERROR.append(err_str)\n",
    "                    ISOK_ALL_PARA = 0\n",
    "                    \n",
    "            # To get the value of REPORT_TYPE\n",
    "            if (re.search(r'REPORT_TYPE\\s?=\\s?(.+)', all_vars[3]) == None):\n",
    "                err_str = 'The format of REPORT_TYPE error.'\n",
    "                if err_str not in GENERAL_ERROR:\n",
    "                    GENERAL_ERROR.append(err_str)\n",
    "                ISOK_ALL_PARA = 0\n",
    "            else:\n",
    "                REPORT_TYPE = re.search(r'REPORT_TYPE\\s?=\\s?(.+)', all_vars[3]).group(1).upper()\n",
    "                if (REPORT_TYPE != 'ALL' and REPORT_TYPE != 'RESOURCE' and REPORT_TYPE != 'CPU' and REPORT_TYPE != 'MEMORY' and REPORT_TYPE != 'IO'):\n",
    "                    err_str = 'The format of REPORT_TYPE error.'\n",
    "                    if err_str not in GENERAL_ERROR:\n",
    "                        GENERAL_ERROR.append(err_str)\n",
    "                    ISOK_ALL_PARA = 0\n",
    "    else:\n",
    "        err_str = 'The format of parameters is error.'\n",
    "        if err_str not in GENERAL_ERROR:\n",
    "            GENERAL_ERROR.append(err_str)\n",
    "        ISOK_ALL_PARA = 0                \n",
    "\n",
    "'''\n",
    "This function is to get all datatime string according to the result \n",
    "queried from database.\n",
    "\n",
    "The variable ori_datetime_str is a dictionary and its data \n",
    "from the combination of hour_list and date_all, which will \n",
    "be used for judging whether some data exists in it or not.\n",
    "'''\n",
    "def get_original_datatime_str(date_all, hour_list):\n",
    "    #To define to dictionary to store the datetime from query result.\n",
    "    ori_datetime_str = {}\n",
    "    for indx in range(len(hour_list)):\n",
    "        #Trans date data to string type\n",
    "        tmp_date_str = date_all[indx].encode('unicode-escape').decode('string_escape')\n",
    "        tmp_hour_str = str(hour_list[indx])\n",
    "        tmp_datetime_str = ''\n",
    "        if(len(tmp_hour_str) == 1):#Change 1:00:00 into 01:00:00\n",
    "            tmp_hour_str = '0' + tmp_hour_str\n",
    "        #Trans date data to string type\n",
    "        tmp_datetime_str = tmp_date_str + ' ' + tmp_hour_str + ':00:00'\n",
    "        ori_datetime_str[tmp_datetime_str] = indx\n",
    "    return ori_datetime_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the required lib\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "#To get all query conditions\n",
    "handle_query_condition()\n",
    "#To print the error of query conditon, only print once\n",
    "for err_id in range(len(GENERAL_ERROR)):\n",
    "    print GENERAL_ERROR[err_id]\n",
    "    \n",
    "if(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'RESOURCE')):\n",
    "    #To declare a Sketchpad as the first graph\n",
    "    pl.figure(figsize = (24, 6))\n",
    "    for idx in range(len(DBs)):\n",
    "        #To get data from the target database for assembling a dataframe which will be used for the following graphs\n",
    "        dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours, sum(total_cpu_usec_delta) / 1000000.0 as cpu_sec, sum(logical_reads_delta) as logical_reads,sum(PHYSICAL_READS_DELTA) as physical_reads,sum(total_act_time)/(sum(act_aborted_total)+sum(act_completed_total)) as avg_activity_time_msec,sum(act_completed_total_delta) as activities from ibm_dsm_views.throughput_all where dbconn_id = '{DBs[idx]}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected), hour(collected) order by date, hours\n",
    "        if dataframe_hour.empty:\n",
    "            print 'For resource(CPU Usage): The query result is empty for the database connection ' + DBs[idx] + ', please check your query parameters.\\n'\n",
    "        else:\n",
    "            #To get the hour data as raw x-axis from the data frame\n",
    "            x_hour = dataframe_hour['HOURS']\n",
    "            #To transfer x_hour to a list type\n",
    "            x_hour_list = list(x_hour) #here x_hour is a python list\n",
    "            #To get the CPU_SEC data as raw y-axis from the data frame\n",
    "            y_cpu_sec = dataframe_hour['CPU_SEC']\n",
    "            #To transfer y_cpu_sec to a list type\n",
    "            y_cpu_sec_list = list(y_cpu_sec)\n",
    "            #The tick of x-axis and sorted by asc\n",
    "            x_ticks = []\n",
    "            #The label of x-axis\n",
    "            x_ticks_lables = []\n",
    "            #To get date data for forming date + hour format\n",
    "            date_all = list(dataframe_hour['DATE'].values)\n",
    "            \n",
    "            x_lable = 'Hours'\n",
    "            \n",
    "            #To get original datetime used followed judgement\n",
    "            ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n",
    "\n",
    "            '''\n",
    "            When the data queried is not equal to the requirement. Filling missing data \n",
    "            into the list x_hour_list,date_all and y_ticks.\n",
    "            '''\n",
    "            if (len(x_hour_list) < INTERVAL):\n",
    "                y_cpu_sec_list = []\n",
    "               \n",
    "                #To transfer datatime data into time tuple for getting its' timestamp\n",
    "                tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                min_timestamp = time.mktime(tm_tuple)\n",
    "\n",
    "                tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                max_timestamp = time.mktime(tmp_tuple)\n",
    "                \n",
    "                '''\n",
    "                To get the difference between the max_timestamp and min_timestamp \n",
    "                which will be used for gaining all date and hour including the missing\n",
    "                '''\n",
    "                hour_diff = int((max_timestamp - min_timestamp) / 3600)\n",
    "                #clear date_all\n",
    "                date_all = []\n",
    "                #clear x_hour_list\n",
    "                x_hour_list = []\n",
    "                #clear y_ticks\n",
    "                y_cpu_sec_list = []\n",
    "                \n",
    "                #Reassign the value of vars above:date_all/x_hour_list/y_cpu_sec_list\n",
    "                for tmp_id in range(hour_diff):\n",
    "                    tmp_st = min_timestamp + tmp_id * 3600\n",
    "                    #To change timestamp to datetime string\n",
    "                    tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n",
    "                    tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "                    tmp_date_str = tmp_datetime_str[0:10]\n",
    "                    tmp_hour_str = tmp_datetime_str[11:13]\n",
    "                    date_all.append(tmp_date_str)\n",
    "                    x_hour_list.append(tmp_hour_str)\n",
    "                    '''\n",
    "                    Below code is for handling y-axis's data\n",
    "                    If there is no data at this hour,0.0 will be filled into\n",
    "                    '''\n",
    "                    if tmp_datetime_str in ori_datetime_str:\n",
    "                        tmp_index = ori_datetime_str[tmp_datetime_str]\n",
    "                        y_cpu_sec_list.append(list(y_cpu_sec)[tmp_index])\n",
    "                    else:\n",
    "                        y_cpu_sec_list.append(0.0)\n",
    "\n",
    "                y_cpu_sec = np.asarray(y_cpu_sec_list)\n",
    "            #The previous date\n",
    "            pre_date_str = str(date_all[0])\n",
    "            \n",
    "            #To form x_ticks and x_ticks_lables\n",
    "            for dateIdx in range(len(date_all)):\n",
    "                #To get the data for the x-axis ticks\n",
    "                x_ticks.append(float('%0.1f' % dateIdx))\n",
    "                '''\n",
    "                Get the data for the lable of x-axis\n",
    "                If the label existed in the list x_ticks_lables,\n",
    "                put hour_str into x_ticks_lables \n",
    "                otherwise,put date_lables into x_ticks_lables\n",
    "                '''\n",
    "                hour_str = str(x_hour_list[dateIdx])\n",
    "                if len(hour_str) == 1:\n",
    "                    hour_str = '0' + hour_str\n",
    "                date_str = str(date_all[dateIdx])\n",
    "                x_lables = date_str + ' ' + hour_str\n",
    "                if (dateIdx == 0):\n",
    "                    x_ticks_lables.append(x_lables)\n",
    "                else:#dateIdx > 0\n",
    "                    if (pre_date_str == date_str):\n",
    "                        x_ticks_lables.append(hour_str)\n",
    "                    else:\n",
    "                        pre_date_str = date_str\n",
    "                        x_ticks_lables.append(x_lables)\n",
    "            #To layout the Sketchpad\n",
    "            rowNo = len(DBs) / 2 + len(DBs) % 2    \n",
    "            arrange = (rowNo * 100) + (2 * 10) + (idx + 1)\n",
    "            plot = pl.subplot(arrange)\n",
    "            \n",
    "            #To set the title for the first graph\n",
    "            figure_title='CPU Usage by Hour(' + DBs[idx] + ')\\n'\n",
    "            pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n",
    "            \n",
    "            #To set x-axis label\n",
    "            pl.xlabel(x_lable, fontsize = 12)\n",
    "            \n",
    "            #To set y-axis label\n",
    "            pl.ylabel(u'CPU_SEC(s)' ,fontsize = 12)\n",
    "            \n",
    "            #To set grid line style according to your requirement\n",
    "            pl.grid(True, ls = '--', color = '#a6266e', alpha = 0.05)\n",
    "            pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n",
    "            \n",
    "            #To mark the the value for per point\n",
    "            for id in range(len(y_cpu_sec_list)):\n",
    "                if(y_cpu_sec_list[id] == 0.0):#If no data,drawing a empty circle\n",
    "                    pl.scatter(x_ticks[id], y_cpu_sec_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n",
    "                else:\n",
    "                    pl.scatter(x_ticks[id], y_cpu_sec_list[id], c = '#2c628b') \n",
    "                    pl.text(x_ticks[id], y_cpu_sec_list[id], '%.2f' % y_cpu_sec_list[id], fontsize = 9)\n",
    "        \n",
    "            #x_hour_isSorted=True do nothing, otherwise, handle data sperately by day\n",
    "            #To smooth the line\n",
    "            xnew_hour = []\n",
    "            ynew_cpu_sec = []\n",
    "            if(len(x_hour_list) >= 3):\n",
    "                ##In order to smooth the line chart,handle the data further##\n",
    "                #Expand each x axis data 10 times\n",
    "                xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size * 20) \n",
    "                #To handle the data of new y axis data\n",
    "                ynew_cpu_sec = spline(np.asarray(x_ticks), y_cpu_sec, xnew_hour)\n",
    "                ynew_cpu_sec_list = list(ynew_cpu_sec)\n",
    "                \n",
    "                #If the value of ynew_cpu_sec_list is negative, then change it into positive\n",
    "                for y_idx in range(len(ynew_cpu_sec_list)):\n",
    "                    if(ynew_cpu_sec_list[y_idx] < 0.0):\n",
    "                        ynew_cpu_sec_list[y_idx] = 0.0\n",
    "                ynew_cpu_sec = np.asarray(ynew_cpu_sec_list)   \n",
    "\n",
    "                #Fill the gragh according to your requirement\n",
    "                plot.fill_between(xnew_hour, ynew_cpu_sec, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#a6266e', alpha = 0.15)\n",
    "\n",
    "                #First draw a smooth line chart using xnew_hour and ynew_memory\n",
    "                plot.plot(xnew_hour, ynew_cpu_sec, color = '#a6266e')\n",
    "                \n",
    "                #To set y-axis value range according to your data\n",
    "                start_value = ynew_cpu_sec.min()-ynew_cpu_sec.min() / 20\n",
    "                start_value = float('%0.2f' % start_value)\n",
    "                end_value = ynew_cpu_sec.max() + ynew_cpu_sec.max() / 20\n",
    "                end_value = float('%0.2f' % end_value)\n",
    "                pl.ylim(float('%0.2f' % start_value), float('%0.2f' % end_value))\n",
    "            else:\n",
    "                y_cpu_sec = list(map(int, y_cpu_sec))\n",
    "                pl.yticks(y_cpu_sec, rotation = 0)\n",
    "    #Show the first graph\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the required lib\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "#To get all query conditions\n",
    "handle_query_condition()\n",
    "        \n",
    "if(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'RESOURCE')):\n",
    "    #Declare a Sketchpad as the first graph\n",
    "    pl.figure(figsize = (24, 4))\n",
    "    for idx in range(len(DBs)):\n",
    "        #Get data from the target database to assemble a data frame that will be used for the following graphs\n",
    "        dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours, sum(total_cpu_usec_delta) / 1000000.0 as cpu_sec,sum(logical_reads_delta) as logical_reads,sum(PHYSICAL_READS_DELTA) as physical_reads,sum(total_act_time)/(sum(act_aborted_total)+sum(act_completed_total)) as avg_activity_time_msec,sum(act_completed_total_delta) as activities from ibm_dsm_views.throughput_all where dbconn_id = '{DBs[idx]}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected), hour(collected) order by date, hours\n",
    "        if dataframe_hour.empty:\n",
    "            print 'For resource(I/O Consumption): The query result is empty for the database connection ' + DBs[idx] + ', please check your query parameters.\\n'\n",
    "        else:\n",
    "            ###Second graph###\n",
    "            #Get the hour data as x-axis from the data frame\n",
    "            x_hour = dataframe_hour['HOURS']\n",
    "            y_logical_reads = dataframe_hour['LOGICAL_READS']\n",
    "            y_logical_reads_list = list(y_logical_reads)\n",
    "\n",
    "            y_physical_reads = dataframe_hour['PHYSICAL_READS']\n",
    "            y_physical_reads_list = list(y_physical_reads)\n",
    "            \n",
    "            log_mil = False\n",
    "            if y_logical_reads.max() > 1000000:\n",
    "                log_mil = True\n",
    "                y_logical_reads = y_logical_reads/1000000\n",
    "        \n",
    "            phy_mil = False\n",
    "            if y_physical_reads.max() > 1000000:\n",
    "                phy_mil = True\n",
    "                y_physical_reads = y_physical_reads/1000000\n",
    "            \n",
    "            x_lable= 'Hours'\n",
    "            x_ticks = []\n",
    "            x_ticks_lables = []\n",
    "            x_hour_list = ''\n",
    "            x_hour_list = list(x_hour) #here x_hour is a python list\n",
    "            date_all = list(dataframe_hour['DATE'].values)\n",
    "\n",
    "            ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n",
    "\n",
    "            '''\n",
    "            When the data queried is not equal to the requirement. Filling missing data \n",
    "            into the list x_hour_list,date_all and y_ticks.\n",
    "            '''\n",
    "            if (len(x_hour_list) < INTERVAL):\n",
    "                y_logical_reads_list = []\n",
    "                y_physical_reads_list = []\n",
    "                #Transfer datatime data into time tuple for getting its' timestamp\n",
    "                tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                min_timestamp = time.mktime(tm_tuple)\n",
    "            \n",
    "                tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                max_timestamp = time.mktime(tmp_tuple)\n",
    "                '''\n",
    "                Get the difference between the max_timestamp and min_timestamp \n",
    "                which will be used for gaining all date and hour including the missing\n",
    "                '''\n",
    "                hour_diff = int((max_timestamp - min_timestamp) / 3600)\n",
    "                #clear date_all\n",
    "                date_all = []\n",
    "                #clear x_hour_list\n",
    "                x_hour_list = []\n",
    "                #clear y_ticks\n",
    "                \n",
    "                #Reassign three var above\n",
    "                for tmp_id in range(hour_diff):\n",
    "                    tmp_st = min_timestamp + tmp_id * 3600\n",
    "                    #Trans timestamp to datetime string\n",
    "                    tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n",
    "                    tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "                    tmp_date_str = tmp_datetime_str[0:10]\n",
    "                    tmp_hour_str = tmp_datetime_str[11:13]\n",
    "                    date_all.append(tmp_date_str)\n",
    "                    x_hour_list.append(tmp_hour_str)\n",
    "                    \n",
    "                    '''\n",
    "                    Below code is for handling y-axis's data\n",
    "                    If there is no data at this hour,0.0 will be filled into\n",
    "                    '''\n",
    "                    if tmp_datetime_str in ori_datetime_str:\n",
    "                        tmp_index = ori_datetime_str[tmp_datetime_str]\n",
    "                        y_logical_reads_list.append(list(y_logical_reads)[tmp_index])\n",
    "                        y_physical_reads_list.append(list(y_physical_reads)[tmp_index])\n",
    "                    else:\n",
    "                        y_logical_reads_list.append(0)\n",
    "                        y_physical_reads_list.append(0)\n",
    "\n",
    "                y_logical_reads = np.asarray(y_logical_reads_list)\n",
    "                y_physical_reads = np.asarray(y_physical_reads_list)\n",
    "            #previous date string value as a reference data\n",
    "            pre_date_str = str(date_all[0])\n",
    "\n",
    "            for dateIdx in range(len(date_all)):\n",
    "                #Get the data for the x-axis ticks\n",
    "                x_ticks.append(float('%0.1f' % dateIdx))\n",
    "                \n",
    "                '''\n",
    "                Get the data for the lable of x-axis\n",
    "                If the label existed in the list x_ticks_lables,\n",
    "                put hour_str into x_ticks_lables \n",
    "                otherwise,put date_lables into x_ticks_lables\n",
    "                '''\n",
    "                hour_str = str(x_hour_list[dateIdx])\n",
    "                if len(hour_str) == 1:\n",
    "                    hour_str = '0' + hour_str\n",
    "                date_str = str(date_all[dateIdx])\n",
    "                x_lables = date_str + ' ' + hour_str\n",
    "                if (dateIdx == 0):\n",
    "                    x_ticks_lables.append(x_lables)\n",
    "                else:#dateIdx > 0\n",
    "                    if (pre_date_str == date_str):\n",
    "                        x_ticks_lables.append(hour_str)\n",
    "                    else:\n",
    "                        pre_date_str = date_str\n",
    "                        x_ticks_lables.append(x_lables)\n",
    "            \n",
    "            rowNo = len(DBs) / 2 + len(DBs) % 2    \n",
    "            arrange = (rowNo * 100) + (2 * 10) + (idx + 1)\n",
    "            ax1 = pl.subplot(arrange)\n",
    "            \n",
    "            x_lable = 'Hours'\n",
    "            pl.xlabel(x_lable, fontsize = 12)\n",
    "            #Set title for the second graph\n",
    "            figure_title='I/O Consumption by Hour(' + DBs[idx] + ')\\n'\n",
    "            pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n",
    "\n",
    "            pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n",
    "            x_hour = np.asarray(x_ticks)\n",
    "            #Draw the first figure using x_hour and y_logical_reads\n",
    "            pl.bar(x_hour-0.15, y_logical_reads, width = 0.3, color = '#2c628b', alpha = 0.5)\n",
    "            #Set y-axis label\n",
    "            if (log_mil==True):\n",
    "                pl.ylabel(u'LOGICAL_READS(mil times)', fontsize = 12)\n",
    "            else:\n",
    "                pl.ylabel(u'LOGICAL_READS(times)',fontsize=12)\n",
    "            pl.grid(True, ls = '-.',color = '#a6266e', linewidth = '.5', alpha = 0.3)\n",
    "            #Set ax1 and ax2 to the same x-axis\n",
    "            ax2 = ax1.twinx()\n",
    "\n",
    "            #Draw the second graph using x_hour and y_physical_reads\n",
    "            pl.bar(x_hour+0.15, y_physical_reads, width = 0.3, color = '#4c78fb', alpha = 0.6)\n",
    "            #Set y-axis lab\n",
    "            if (phy_mil==True):\n",
    "                pl.ylabel(u'PHYSICAL_READS(mil times)', fontsize = 12)\n",
    "            else:\n",
    "                pl.ylabel(u'PHYSICAL_READS(times)', fontsize = 12)\n",
    "\n",
    "            #Set legend for the ax1 contioner\n",
    "            ax1.legend(['LOGICAL_READS'], loc = 'upper right', bbox_to_anchor = (0.5, 1.11), ncol = 1)\n",
    "            #Set legend for the ax2 contioner\n",
    "            ax2.legend(['PHYSICAL_READS'], loc = 'upper right', bbox_to_anchor = (0.7, 1.11), fancybox = True, shadow = True, ncol = 1)\n",
    "            #Set grid format\n",
    "            pl.grid(True, ls = '-.', color = '#a6266e', linewidth = '0.5', alpha = 0.3)\n",
    "    #Show the first graph\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the required lib\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "#To get all query conditions\n",
    "handle_query_condition()\n",
    "        \n",
    "if(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'RESOURCE')):\n",
    "    #Declare a Sketchpad as the first graph\n",
    "    pl.figure(figsize = (24, 3))\n",
    "    for idx in range(len(DBs)):\n",
    "        #Get data from the target database to assemble a data frame that will be used for the following graphs\n",
    "        dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours, sum(total_cpu_usec_delta) / 1000000.0 as cpu_sec,sum(logical_reads_delta) as logical_reads,sum(PHYSICAL_READS_DELTA) as physical_reads,sum(total_act_time)/(sum(act_aborted_total)+sum(act_completed_total)) as avg_activity_time_msec,sum(act_completed_total_delta) as activities from ibm_dsm_views.throughput_all where dbconn_id = '{DBs[idx]}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected), hour(collected) order by date, hours\n",
    "        if dataframe_hour.empty:\n",
    "            print 'For resource(Average Activity Time): The query result is empty for the database connection ' + DBs[idx] + ', please check your query parameters.\\n'\n",
    "        else:\n",
    "            ###The third graph###\n",
    "            \n",
    "            #Get the hour data as x-axis from the data frame\n",
    "            x_hour = dataframe_hour['HOURS']\n",
    "\n",
    "            y_avg_act = dataframe_hour['AVG_ACTIVITY_TIME_MSEC']\n",
    "            y_avg_act_list = list(y_avg_act)\n",
    "\n",
    "            x_ticks = []\n",
    "            x_ticks_lables = []\n",
    "\n",
    "            x_hour_list = list(x_hour) #here x_hour is a python list\n",
    "            date_all = list(dataframe_hour['DATE'].values)\n",
    "\n",
    "            ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n",
    "\n",
    "            '''\n",
    "            When the data queried is not equal to the requirement. Filling missing data \n",
    "            into the list x_hour_list,date_all and y_ticks.\n",
    "            '''\n",
    "            if (len(x_hour_list) < INTERVAL):\n",
    "                y_avg_act_list = []\n",
    "                #Transfer datatime data into time tuple for getting its' timestamp\n",
    "                tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                min_timestamp = time.mktime(tm_tuple)\n",
    "\n",
    "                tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                max_timestamp = time.mktime(tmp_tuple)\n",
    "                '''\n",
    "                Get the difference between the max_timestamp and min_timestamp \n",
    "                which will be used for gaining all date and hour including the missing\n",
    "                '''\n",
    "                hour_diff = int((max_timestamp - min_timestamp) / 3600)\n",
    "                #clear date_all\n",
    "                date_all = []\n",
    "                #clear x_hour_list\n",
    "                x_hour_list = []\n",
    "                #Reassign three var above\n",
    "                for tmp_id in range(hour_diff):\n",
    "                    tmp_st = min_timestamp + tmp_id * 3600\n",
    "                    #Trans timestamp to datetime string\n",
    "                    tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n",
    "                    tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "                    tmp_date_str = tmp_datetime_str[0:10]\n",
    "                    tmp_hour_str = tmp_datetime_str[11:13]\n",
    "                    date_all.append(tmp_date_str)\n",
    "                    x_hour_list.append(tmp_hour_str)\n",
    "                    '''\n",
    "                    Below code is for handling y-axis's data\n",
    "                    If there is no data at this hour,0.0 will be filled into\n",
    "                    '''\n",
    "                    if tmp_datetime_str in ori_datetime_str:\n",
    "                        tmp_index = ori_datetime_str[tmp_datetime_str]\n",
    "                        y_avg_act_list.append(list(y_avg_act)[tmp_index])\n",
    "                    else:\n",
    "                        y_avg_act_list.append(0)\n",
    "\n",
    "                y_avg_act = np.asarray(y_avg_act_list)\n",
    "            #previous date string value as a reference data\n",
    "            pre_date_str = str(date_all[0])\n",
    "\n",
    "            for dateIdx in range(len(date_all)):\n",
    "                #Get the data for the x-axis ticks\n",
    "                x_ticks.append(float('%0.1f' % dateIdx))\n",
    "                '''\n",
    "                Get the data for the lable of x-axis\n",
    "                If the label existed in the list x_ticks_lables,\n",
    "                put hour_str into x_ticks_lables \n",
    "                otherwise,put date_lables into x_ticks_lables\n",
    "                '''\n",
    "                hour_str = str(x_hour_list[dateIdx])\n",
    "                if len(hour_str) == 1:\n",
    "                    hour_str = '0' + hour_str\n",
    "                date_str = str(date_all[dateIdx])\n",
    "                x_lables = date_str + ' ' + hour_str\n",
    "                if (dateIdx == 0):\n",
    "                    x_ticks_lables.append(x_lables)\n",
    "                else:#dateIdx > 0\n",
    "                    if (pre_date_str == date_str):\n",
    "                        x_ticks_lables.append(hour_str)\n",
    "                    else:\n",
    "                        pre_date_str = date_str\n",
    "                        x_ticks_lables.append(x_lables)\n",
    "            \n",
    "            rowNo = len(DBs) / 2 + len(DBs) % 2 \n",
    "            arrange = (rowNo * 100) + (2 * 10) + (idx + 1)\n",
    "            ax1 = pl.subplot(arrange)\n",
    "            \n",
    "            #Set title for the second graph\n",
    "            figure_title='Average Activity Time by Hour(' + DBs[idx] + ')\\n'\n",
    "            pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n",
    "            pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n",
    "            x_hour = np.asarray(x_ticks)\n",
    "            pl.ylabel(u'AVG_ACTIVITY_TIME_MSEC', fontsize = 12)\n",
    "            pl.xlabel(x_lable, fontsize = 12)\n",
    "            #Set grid line style according to your requirement\n",
    "            pl.grid(True, ls = '--', color = '#a6266e', alpha = 0.05)\n",
    "            #x_hour_isSorted=True do nothing, otherwise, handle data sperately by day\n",
    "            \n",
    "            for id in range(len(y_avg_act_list)):\n",
    "                if(y_avg_act_list[id] == 0.0):#If no data,drawing a empty circle\n",
    "                    pl.scatter(x_ticks[id], y_avg_act_list[id], c = '', marker = 'o', edgecolors = 'r', s = 50)\n",
    "                else:\n",
    "                    pl.scatter(x_ticks[id], y_avg_act_list[id], c = '#2c628b') \n",
    "                    pl.text(x_ticks[id], y_avg_act_list[id], '%.0f' % y_avg_act_list[id], fontsize = 9)\n",
    "\n",
    "            #x_hour_isSorted=True do nothing, otherwise, handle data sperately by day\n",
    "            xnew_hour = []\n",
    "            ynew_cpu_sec = []\n",
    "        \n",
    "            if(len(x_hour_list) >= 3):\n",
    "                xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size * 20) \n",
    "                #Handle the data of new y axis data\n",
    "                ynew_avg_act = spline(np.asarray(x_ticks), y_avg_act,xnew_hour)\n",
    "                \n",
    "                ynew_avg_act_list = list(ynew_avg_act)\n",
    "                #No negative value for y-axis\n",
    "                for y_idx in range(len(ynew_avg_act_list)):\n",
    "                    if (ynew_avg_act_list[y_idx] < 0.0):\n",
    "                        ynew_avg_act_list[y_idx] = 0.0\n",
    "                ynew_avg_act = np.asarray(ynew_avg_act_list)\n",
    "                \n",
    "                #Fill the gragh according to your requirement\n",
    "                pl.fill_between(xnew_hour, ynew_avg_act, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#a6266e', alpha = 0.15)\n",
    "                #First draw a smooth line chart using xnew_hour and ynew_memory\n",
    "                pl.plot(xnew_hour, ynew_avg_act, color = '#a6266e')\n",
    "                #Set y-axis value range according to your data\n",
    "                start_value = ynew_avg_act.min() - ynew_avg_act.min() / 2\n",
    "                start_value = float('%0.2f' % start_value)\n",
    "                end_value = ynew_avg_act.max() + ynew_avg_act.max() / 2\n",
    "                end_value = float('%0.2f' % end_value)\n",
    "                pl.ylim(float('%0.2f' % start_value), float('%0.2f' % end_value))\n",
    "            else:\n",
    "                y_avg_act_list = list(map(int, y_avg_act_list))\n",
    "                pl.yticks(y_avg_act_list, rotation = 0)\n",
    "    #Show the first graph\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the required lib\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "#To get all query conditions\n",
    "handle_query_condition()\n",
    "        \n",
    "if(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'CPU')):\n",
    "    #Declare a Sketchpad including two graphs of left and right distribution\n",
    "    pl.figure(figsize=(24,6))\n",
    "    for idx in range(len(DBs)):\n",
    "        #Get data from the target database to assemble a data frame that will be used for the following graphs\n",
    "        dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours, sum(db2_cpu_user_delta) as db2_cpu_user, 100*sum(db2_cpu_user_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as db2_cpu_user_percent, sum(db2_cpu_system_delta) as db2_cpu_system,  100*sum(db2_cpu_system_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as db2_cpu_system_percent,sum(cpu_user_delta) as cpu_user,  100*sum(cpu_user_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as cpu_user_percent,sum(cpu_system_delta) as cpu_system,  100*sum(cpu_system_delta)/(sum(cpu_user_delta) + sum(cpu_system_delta) + sum(cpu_iowait_delta)+ sum(cpu_idle_delta)) as cpu_system_percent from IBM_DSM_VIEWS.THROUGHPUT_SYSTEM where dbconn_id='{DBs[idx]}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected),hour(collected) order by date,hours\n",
    "        if dataframe_hour.empty:\n",
    "            print 'For cpu: The query result is empty for the database connection ' + DBs[idx] + ', please check your query parameters.\\n'\n",
    "        else:\n",
    "            #Get the hour data as x-axis from the data frame\n",
    "            x_hour = dataframe_hour['HOURS']\n",
    "            #Get the db2_cpu_user_percent data as top y-axis of the first graph from the data frame\n",
    "            y_db2_user = dataframe_hour['DB2_CPU_USER_PERCENT']\n",
    "            y_db2_user_list = []\n",
    "            #Get the db2_cpu_system_percent data as bottom y-axis of the first graph from the data frame\n",
    "            y_db2_sys = dataframe_hour['DB2_CPU_SYSTEM_PERCENT']\n",
    "            y_db2_sys_list = []\n",
    "            #Get the cpu_user_percent data as top y-axis of the second graph from the data frame\n",
    "            y_cpu_user = dataframe_hour['CPU_USER_PERCENT']\n",
    "            y_cpu_user_list = []\n",
    "            #Get the cpu_system_percent data as bottom y-axis of the second graph from the data frame\n",
    "            y_cpu_sys = dataframe_hour['CPU_SYSTEM_PERCENT']\n",
    "            y_cpu_sys_list = []\n",
    "\n",
    "            x_ticks = []\n",
    "            x_ticks_lables = []\n",
    "            x_hour_list = list(x_hour)\n",
    "            date_all = list(dataframe_hour['DATE'].values)\n",
    "\n",
    "            ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n",
    "\n",
    "            '''\n",
    "            When the data queried is not equal to the requirement. Filling missing data \n",
    "            into the list x_hour_list,date_all and y_ticks.\n",
    "            '''\n",
    "            if (len(x_hour_list) < INTERVAL):\n",
    "                #Transfer datatime data into time tuple for getting its' timestamp\n",
    "                tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                min_timestamp = time.mktime(tm_tuple)\n",
    "\n",
    "                max_date = date_all[len(date_all)-1].encode('unicode-escape').decode('string_escape')\n",
    "                max_date_hour = str(x_hour_list[len(date_all) - 1])\n",
    "                dt_str = max_date + ' ' + max_date_hour + ':00:00'\n",
    "                tmp_tuple = time.strptime(dt_str, '%Y-%m-%d %H:%M:%S')\n",
    "                max_timestamp = time.mktime(tmp_tuple)\n",
    "                '''\n",
    "                Get the difference between the max_timestamp and min_timestamp \n",
    "                which will be used for gaining all date and hour including the missing\n",
    "                '''\n",
    "                hour_diff = int((max_timestamp - min_timestamp) / 3600)\n",
    "                #clear date_all\n",
    "                date_all = []\n",
    "                #clear x_hour_list\n",
    "                x_hour_list = []\n",
    "\n",
    "                #Reassign three var above\n",
    "                for tmp_id in range(hour_diff):\n",
    "                    tmp_st = min_timestamp + tmp_id * 3600\n",
    "                    #Trans timestamp to datetime string\n",
    "                    tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n",
    "                    tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "                    tmp_date_str = tmp_datetime_str[0:10]\n",
    "                    tmp_hour_str = tmp_datetime_str[11:13]\n",
    "                    date_all.append(tmp_date_str)\n",
    "                    x_hour_list.append(tmp_hour_str)\n",
    "                    '''\n",
    "                    Below code is for handling y-axis's data\n",
    "                    If there is no data at this hour,0.0 will be filled into\n",
    "                    '''\n",
    "                    if tmp_datetime_str in ori_datetime_str:\n",
    "                        tmp_index = ori_datetime_str[tmp_datetime_str]\n",
    "                        y_db2_user_list.append(list(y_db2_user)[tmp_index])\n",
    "                        y_db2_sys_list.append(list(y_db2_sys)[tmp_index])\n",
    "                        y_cpu_user_list.append(list(y_cpu_user)[tmp_index])\n",
    "                        y_cpu_sys_list.append(list(y_cpu_sys)[tmp_index])\n",
    "                    else:\n",
    "                        y_db2_user_list.append(0)\n",
    "                        y_db2_sys_list.append(0)\n",
    "                        y_cpu_user_list.append(0)\n",
    "                        y_cpu_sys_list.append(0)\n",
    "                y_db2_user = np.asarray(y_db2_user_list)\n",
    "                y_db2_sys = np.asarray(y_db2_sys_list)\n",
    "                y_cpu_user = np.asarray(y_cpu_user_list)\n",
    "                y_cpu_sys = np.asarray(y_cpu_sys_list)\n",
    "\n",
    "            #previous date string value as a reference data\n",
    "            pre_date_str = str(date_all[0])\n",
    "\n",
    "            for dateIdx in range(len(date_all)):\n",
    "                #Get the data for the x-axis ticks\n",
    "                x_ticks.append(float('%0.1f' % dateIdx))\n",
    "                '''\n",
    "                Get the data for the lable of x-axis\n",
    "                If the label existed in the list x_ticks_lables,\n",
    "                put hour_str into x_ticks_lables \n",
    "                otherwise,put date_lables into x_ticks_lables\n",
    "                '''\n",
    "                hour_str = str(x_hour_list[dateIdx])\n",
    "                if len(hour_str) == 1:\n",
    "                    hour_str = '0' + hour_str\n",
    "                date_str = str(date_all[dateIdx])\n",
    "                x_lables = date_str + ' ' + hour_str\n",
    "                if (dateIdx == 0):\n",
    "                    x_ticks_lables.append(x_lables)\n",
    "                else:#dateIdx > 0\n",
    "                    if (pre_date_str == date_str):\n",
    "                        x_ticks_lables.append(hour_str)\n",
    "                    else:\n",
    "                        pre_date_str = date_str\n",
    "                        x_ticks_lables.append(x_lables)\n",
    "            \n",
    "            rowNo = len(DBs) / 2 + len(DBs) % 2    \n",
    "            arrange = (rowNo * 100) + (2 * 10) + (idx + 1)\n",
    "            ax1 = pl.subplot(arrange)\n",
    "            \n",
    "            #Set the title for the left graph\n",
    "            figure_title = 'CPU Utilization by Hour(' + DBs[idx] + ')\\n'\n",
    "            pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n",
    "            \n",
    "            pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n",
    "\n",
    "            #Set y-axis label\n",
    "            pl.ylabel(u'CPU %', fontsize = 12)\n",
    "            #Set x-axis label\n",
    "            x_lable= 'Hours'\n",
    "            #Set x-axis label\n",
    "            pl.xlabel(x_lable, fontsize = 12)\n",
    "            \n",
    "            x_hour = np.asarray(x_ticks)\n",
    "            #Draw the top y-axis of the upper graph\n",
    "            pl.bar(x_hour - 0.2, y_db2_user, width = 0.4, align = 'center', color = '#60bdae')\n",
    "            #Draw the bottom y-axis of the upper graph\n",
    "            pl.bar(x_hour - 0.2, y_db2_sys, width = 0.4, align = 'center', color = '#a6266e', bottom = y_db2_user)\n",
    "            #Draw the top y-axis of the lower graph\n",
    "            pl.bar(x_hour + 0.2, y_cpu_user, width = 0.4, color = '#4c78fb')\n",
    "            #Draw the bottom y-axis of the lower graph\n",
    "            pl.bar(x_hour + 0.2, y_cpu_sys, width = 0.4, color = '#2c628b', bottom = y_cpu_user)\n",
    "            \n",
    "            pl.yticks(np.arange(0, 101, 10))\n",
    "            \n",
    "            #Set the legends for the left graph\n",
    "            box = ax1.get_position()\n",
    "            ax1.set_position([box.x0, box.y0 + box.height * 0.1,box.width, box.height * 0.9])\n",
    "            ax1.legend(['DB2_CPU_USER_PERCENT', 'DB2_CPU_SYSTEM_PERCENT', 'CPU_USER_PERCENT', 'CPU_SYSTEM_PERCENT'], fontsize = 9, loc = 'upper center', bbox_to_anchor = (0.5, 1.06), fancybox = True, shadow = True, ncol = 4)\n",
    "            #Set grid format for ax1\n",
    "            pl.grid(True, ls = '-.', color = '#a6266e', linewidth = '0.2', alpha = 0.7)\n",
    "    #Show all graphs\n",
    "    pl.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import the required lib\n",
    "import pylab as pl\n",
    "\n",
    "#To get all query conditions\n",
    "handle_query_condition()\n",
    "        \n",
    "if(ISOK_ALL_PARA and (REPORT_TYPE == 'ALL' or REPORT_TYPE == 'MEMORY')):\n",
    "    #Declare a Sketchpad as the first graph\n",
    "    pl.figure(figsize = (24, 6))\n",
    "    for idx in range(len(DBs)):\n",
    "        #Get data from the target database to assemble a data frame that will be used for the following graphs\n",
    "        dataframe_hour = %sql select char(date(collected)) as date, hour(collected) as hours,dec(max(memory_pool_used_gb), 17, 2) as memory_usage_gb from IBM_DSM_VIEWS.MEM_DB_TOTAL_USED where dbconn_id = '{DBs[idx]}' and collected >= '{START_TIME}' and collected < '{END_TIME}' group by date(collected), hour(collected) order by date, hours\n",
    "        if dataframe_hour.empty:\n",
    "            print 'For memory: The query result is empty for the database connection ' + DBs[idx] + ', please check your query parameters.\\n'\n",
    "        else:\n",
    "            #Get the hour data as x-axis from the data frame and convert the data into a numpy array\n",
    "            x_hour= dataframe_hour['HOURS'].values\n",
    "            y_memory = dataframe_hour['MEMORY_USAGE_GB'].values\n",
    "            \n",
    "            #Define a empty var x_ticks to store x-axis ticks(marks)\n",
    "            x_ticks = []\n",
    "            #Define a empty var x_ticks_lables to restore x-axis labels\n",
    "            x_ticks_lables = []\n",
    "            #Define a empty var y_ticks to store y-axis ticks(marks)\n",
    "            y_memory_list = list(y_memory)\n",
    "            \n",
    "            x_hour_list = list(x_hour) #here x_hour is a python list\n",
    "            date_all = list(dataframe_hour['DATE'].values)\n",
    "            \n",
    "            ori_datetime_str = get_original_datatime_str(date_all, x_hour_list)\n",
    "\n",
    "            '''\n",
    "            When the data queried is not equal to the requirement. Filling missing data \n",
    "            into the list x_hour_list,date_all and y_ticks.\n",
    "            '''\n",
    "            if (len(x_hour_list) < INTERVAL):\n",
    "                #Transfer datatime data into time tuple for getting its' timestamp\n",
    "                tm_tuple = time.strptime(START_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                min_timestamp = time.mktime(tm_tuple)\n",
    "\n",
    "                tmp_tuple = time.strptime(END_TIME, '%Y-%m-%d %H:%M:%S')\n",
    "                max_timestamp = time.mktime(tmp_tuple)\n",
    "                '''\n",
    "                Get the difference between the max_timestamp and min_timestamp \n",
    "                which will be used for gaining all date and hour including the missing\n",
    "                '''\n",
    "                hour_diff = int((max_timestamp - min_timestamp) / 3600)\n",
    "                #clear date_all\n",
    "                date_all = []\n",
    "                #clear x_hour_list\n",
    "                x_hour_list = []\n",
    "                #clear y_ticks\n",
    "                tmp_y_ticks = []\n",
    "                #Reassign three var above\n",
    "\n",
    "                for tmp_id in range(hour_diff):\n",
    "                    tmp_st = min_timestamp + tmp_id * 3600\n",
    "                    #Trans timestamp to datetime string\n",
    "                    tmp_datetime = datetime.datetime.fromtimestamp(tmp_st)\n",
    "                    tmp_datetime_str = tmp_datetime.strftime(\"%Y-%m-%d %H:00:00\")\n",
    "                    tmp_date_str = tmp_datetime_str[0:10]\n",
    "                    tmp_hour_str = tmp_datetime_str[11:13]\n",
    "                    date_all.append(tmp_date_str)\n",
    "                    x_hour_list.append(tmp_hour_str)\n",
    "                    '''\n",
    "                    Below code is for handling y-axis's data\n",
    "                    If there is no data at this hour,0.0 will be filled into\n",
    "                    '''\n",
    "                    if tmp_datetime_str in ori_datetime_str:\n",
    "                        tmp_index = ori_datetime_str[tmp_datetime_str]\n",
    "                        tmp_y_ticks.append(y_memory_list[tmp_index])\n",
    "                    else:\n",
    "                        tmp_y_ticks.append(0.0)\n",
    "                y_memory_list = tmp_y_ticks\n",
    "\n",
    "            #previous date string value as a reference data\n",
    "            pre_date_str = str(date_all[0])\n",
    "\n",
    "            for dateIdx in range(len(date_all)):\n",
    "                #Get the data for the x-axis ticks\n",
    "                x_ticks.append(float('%0.1f' % dateIdx))\n",
    "                '''\n",
    "                Get the data for the lable of x-axis\n",
    "                If the label existed in the list x_ticks_lables,\n",
    "                put hour_str into x_ticks_lables \n",
    "                otherwise,put date_lables into x_ticks_lables\n",
    "                '''\n",
    "                hour_str = str(x_hour_list[dateIdx])\n",
    "                if len(hour_str) == 1:\n",
    "                    hour_str = '0' + hour_str\n",
    "                date_str = str(date_all[dateIdx])\n",
    "                x_lables = date_str + ' ' + hour_str\n",
    "                if (dateIdx == 0):\n",
    "                    x_ticks_lables.append(x_lables)\n",
    "                else:#dateIdx > 0\n",
    "                    if (pre_date_str == date_str):\n",
    "                        x_ticks_lables.append(hour_str)\n",
    "                    else:\n",
    "                        pre_date_str = date_str\n",
    "                        x_ticks_lables.append(x_lables)\n",
    "            \n",
    "            rowNo_mry = len(DBs) / 2 + len(DBs) % 2\n",
    "            arrange_mry = (rowNo_mry * 100) + (2 * 10) + (idx + 1)\n",
    "            plot = pl.subplot(arrange_mry)\n",
    "            \n",
    "            #Get the data as the label of x-axis\n",
    "            #Set the title for the graph\n",
    "            figure_title='Memory Usage by Hour(' + DBs[idx] + ')\\n'\n",
    "            pl.title(figure_title, fontsize = 14, fontweight = 'bold')\n",
    "            pl.xticks(x_ticks, x_ticks_lables, rotation = 90)\n",
    "            #Set x-axis label\n",
    "            x_lable= 'Hours'\n",
    "            pl.xlabel(x_lable, fontsize = 12)\n",
    "            #Set y-axis label\n",
    "            pl.ylabel(u'MEMORY_USAGE(GB)', fontsize = 12)\n",
    "            #Set grid line style according to your requirement\n",
    "            pl.grid(True, ls = '--', color = '#2c628b', alpha = 0.05)\n",
    "            \n",
    "            for id in range(len(y_memory_list)):\n",
    "                if(y_memory_list[id] == 0.0):#If no data,drawing a empty circle\n",
    "                    pl.scatter(x_ticks[id], y_memory_list[id], c = '',marker = 'o', edgecolors = 'r', s = 50)\n",
    "                else:\n",
    "                    pl.scatter(x_ticks[id], y_memory_list[id], c = '#2c628b') \n",
    "                    pl.text(x_ticks[id], y_memory_list[id], '%.2f' % y_memory_list[id], fontsize = 9)\n",
    "            \n",
    "            #Below two variable is used for storeing magnified data\n",
    "            xnew_hour = []\n",
    "            ynew_memory = []\n",
    "            #if the size of data is greater than 2,showing a line not a scatter\n",
    "            #otherwise, a scatter graph will be showed\n",
    "            if(len(x_hour_list) >= 3):\n",
    "                #Get the memory_usage_gb data as y-axis from the data frame and convert the data into a numpy array\n",
    "                ##In order to smooth the line chart,handle the data further##\n",
    "                #Expand each x axis data 20 times\n",
    "                xnew_hour = np.linspace(np.asarray(x_ticks).min(), np.asarray(x_ticks).max(), np.asarray(x_ticks).size*20) \n",
    "                #Handle the data of new y axis data\n",
    "                ynew_memory = spline(np.asarray(x_ticks), np.asarray(y_memory_list), xnew_hour)\n",
    "                \n",
    "                ynew_memory_list = list(ynew_memory)\n",
    "                #No negative value for y-axis\n",
    "                for y_idx in range(len(ynew_memory_list)):\n",
    "                    if (ynew_memory_list[y_idx] < 0.0):\n",
    "                        ynew_memory_list[y_idx] = 0.0\n",
    "                ynew_memory = np.asarray(ynew_memory_list)\n",
    "                \n",
    "                #Fill the gragh according to your requirement\n",
    "                plot.fill_between(xnew_hour,ynew_memory, where=(xnew_hour.min()<xnew_hour) & (xnew_hour<xnew_hour.max()), color = '#2c628b', alpha = 0.09)\n",
    "               \n",
    "                #First draw a smooth line chart using xnew_hour and ynew_memory\n",
    "                plot.plot(xnew_hour, ynew_memory, color = '#2c628b')\n",
    "\n",
    "                #Set y-axis value range according to your data\n",
    "                start_value=ynew_memory.min() - ynew_memory.min() / 2\n",
    "                start_value=float('%0.2f' % start_value)\n",
    "                end_value=ynew_memory.max() + ynew_memory.max() / 2\n",
    "                end_value=float('%0.2f' % end_value)\n",
    "                if((start_value == 0.0) and (end_value == 0.0)):\n",
    "                    y_memory_list = list(map(int, y_memory_list))\n",
    "                    pl.yticks(y_memory_list, rotation = 0)\n",
    "                else:\n",
    "                    pl.ylim(float('%0.2f' % start_value), float('%0.2f' % end_value))\n",
    "            else:\n",
    "                y_memory_list = list(map(int, y_memory_list))\n",
    "                pl.yticks(y_memory_list,rotation=0)\n",
    "                \n",
    "    #Show the graph\n",
    "    pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with DSX Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
